{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbf05c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stagiaire-stack/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-06-03 09:11:01,853\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n",
      "Flower 1.17.0 / PyTorch 2.6.0+cu124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stagiaire-stack/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "import flwr\n",
    "from flwr.client import Client, ClientApp, NumPyClient\n",
    "from flwr.common import Context\n",
    "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
    "from flwr.server.strategy import Strategy\n",
    "from flwr.simulation import run_simulation\n",
    "# from flwr_datasets import FederatedDataset\n",
    "from typing import Union\n",
    "from flwr.server.client_proxy import ClientProxy  # Correctly import ClientProxy\n",
    "from flwr.common import FitRes, Parameters\n",
    "from torch.optim import lr_scheduler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import glob\n",
    "import os\n",
    "from typing import Union\n",
    "from flwr.common import (\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    Parameters,\n",
    "    Scalar,\n",
    "    ndarrays_to_parameters,\n",
    "    parameters_to_ndarrays,\n",
    ")\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from flwr_datasets.partitioner import IidPartitioner\n",
    "from flwr.server.client_manager import ClientManager\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.server.strategy.aggregate import aggregate, weighted_loss_avg\n",
    "from flwr.server.strategy import FedAvg\n",
    "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9a3ee87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NUM_CLIENTS = 15\n",
    "BATCH_SIZE = 64\n",
    "MAX_ROUND = 10\n",
    "NUM_PARTITIONS = NUM_CLIENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dcffb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f280129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from flwr_datasets.partitioner import IidPartitioner\n",
    "from flwr_datasets import FederatedDataset\n",
    "class AttackDataset(Dataset):\n",
    "    def __init__(self, hf_dataset):\n",
    "        self.dataset = hf_dataset\n",
    "        self.feature_keys = [k for k in hf_dataset.column_names if k != \"Attack_type\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "            item = self.dataset[idx]\n",
    "            X = torch.tensor([item[k] for k in self.feature_keys], dtype=torch.float32)\n",
    "            y = torch.tensor(item[\"Attack_type\"], dtype=torch.long)\n",
    "            return X, y\n",
    "\n",
    "\n",
    "def load_datasets(partition_id: int, num_partitions: int, min_dataset_size=50):\n",
    "    data_files = {\n",
    "        \"train\": \"preprocessed_DNN-EdgeIIoT-dataset.csv\"\n",
    "    }\n",
    "\n",
    "    \n",
    "\n",
    "    # Charge tout le DatasetDict\n",
    "    dataset_dict = load_dataset(\"csv\", data_files=data_files)\n",
    "    dataset_dict = dataset_dict.remove_columns([\"Attack_label\"])\n",
    "    # Prend uniquement le split 'train' pour le partitionnement\n",
    "    train_dataset = dataset_dict[\"train\"]\n",
    "\n",
    "    # Partitionnement\n",
    "    partitioner = IidPartitioner(num_partitions=num_partitions)\n",
    "    partitioner.dataset = train_dataset\n",
    "\n",
    "    client_dataset = partitioner.load_partition(partition_id)\n",
    "\n",
    "    if len(client_dataset) < min_dataset_size:\n",
    "        raise ValueError(f\"Partition {partition_id} trop petite ({len(client_dataset)} échantillons), minimum requis = {min_dataset_size}\")\n",
    "\n",
    "    # Split local train/val/test : 70% / 15% / 15%\n",
    "    train_val_test = client_dataset.train_test_split(test_size=0.3, seed=42)\n",
    "    val_test = train_val_test[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
    "\n",
    "    train_set = AttackDataset(train_val_test[\"train\"])\n",
    "    val_set = AttackDataset(val_test[\"train\"])\n",
    "    test_set = AttackDataset(val_test[\"test\"])\n",
    "\n",
    "    # DataLoaders\n",
    "    trainloader = DataLoader(train_set, batch_size=32, shuffle=True, num_workers=4)\n",
    "    valloader = DataLoader(val_set, batch_size=32, shuffle=False, num_workers=4)\n",
    "    testloader = DataLoader(test_set, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "    return trainloader, valloader, testloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abd4f5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size=96, num_classes=15):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 90),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(90, 90),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(90, num_classes)  # output logits pour chaque classe\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20b4d98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "def train(net, trainloader, epochs: int):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=1e-5)  # L2 régularisation ici    \n",
    "    scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[50, 75], gamma=0.1)\n",
    "\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for X, y in trainloader:\n",
    "            X, y = X.to(DEVICE), y.to(DEVICE)  # y doit rester en long pour CrossEntropy\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(X)  # shape: [B, 15]\n",
    "            outputs = F.softmax(outputs, dim=1)\n",
    "\n",
    "            # print(\"outputs\")\n",
    "            # print(outputs)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "            # Prédictions\n",
    "            correct += (outputs.argmax(dim=1) == y).sum().item()\n",
    "            total += y.size(0)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        epoch_loss /= len(trainloader)\n",
    "        epoch_acc = correct / total\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: train loss {epoch_loss:.4f}, accuracy {epoch_acc:.4f}\")\n",
    "\n",
    "\n",
    "def test(net, testloader):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    correct, total, total_loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in testloader:\n",
    "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "            outputs = net(X)  # shape: [B, 15]\n",
    "            _, predicted = outputs.max(1)\n",
    "\n",
    "            loss = criterion(outputs, y)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(testloader)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dea070b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(NumPyClient):\n",
    "    def __init__(self, partition_id, net, trainloader, valloader):\n",
    "        self.partition_id = partition_id\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.partition_id}] get_parameters\")\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] fit, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=3)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "\n",
    "def client_fn(context: Context) -> Client:\n",
    "    net = MLP().to(DEVICE)\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    num_partitions = context.node_config[\"num-partitions\"]\n",
    "    trainloader, valloader, _ = load_datasets(partition_id, num_partitions)\n",
    "    return FlowerClient(partition_id, net, trainloader, valloader).to_client()\n",
    "\n",
    "\n",
    "# Create the ClientApp\n",
    "client = ClientApp(client_fn=client_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cdce9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flwr as fl\n",
    "\n",
    "net = MLP()\n",
    "\n",
    "class SaveModelStrategy(fl.server.strategy.FedAvg):\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: list[tuple[fl.server.client_proxy.ClientProxy, fl.common.FitRes]],\n",
    "        failures: list[Union[tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> tuple[Optional[Parameters], dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate model weights using weighted average and store checkpoint\"\"\"\n",
    "        print(f\"Results from clients: {results}\")  # Debugging line\n",
    "        # Call aggregate_fit from base class (FedAvg) to aggregate parameters and metrics\n",
    "        aggregated_parameters, aggregated_metrics = super().aggregate_fit(\n",
    "            server_round, results, failures\n",
    "        )\n",
    "\n",
    "        if server_round == MAX_ROUND:\n",
    "\n",
    "            if aggregated_parameters is not None:\n",
    "                print(f\"Saving round {server_round} aggregated_parameters...\")\n",
    "\n",
    "                # Convert `Parameters` to `list[np.ndarray]`\n",
    "                aggregated_ndarrays: list[np.ndarray] = fl.common.parameters_to_ndarrays(\n",
    "                    aggregated_parameters\n",
    "                )\n",
    "                # Convert `list[np.ndarray]` to PyTorch `state_dict`\n",
    "                params_dict = zip(net.state_dict().keys(), aggregated_ndarrays)\n",
    "                state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "                net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "                # Save the model to disk\n",
    "                torch.save(net.state_dict(), f\"model/model_round_{server_round}.pth\")\n",
    "\n",
    "        return aggregated_parameters, aggregated_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5e273fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.common import NDArrays\n",
    "def evaluate(\n",
    "    server_round: int,\n",
    "    parameters: NDArrays,\n",
    "    config: Dict[str, Scalar],\n",
    ") -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "    net = MLP().to(DEVICE)\n",
    "    _, _, testloader = load_datasets(0, NUM_PARTITIONS)\n",
    "    set_parameters(net, parameters)  # Update model with the latest parameters\n",
    "    loss, accuracy = test(net, testloader)\n",
    "    print(f\"Server-side evaluation loss {loss} / accuracy {accuracy}\")\n",
    "    return loss, {\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b75d8092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create strategy and pass into ServerApp\n",
    "def server_fn(context):\n",
    "    strategy = SaveModelStrategy(\n",
    "        fraction_fit=1.0,  # Utiliser 100% des clients pour l'entraînement\n",
    "        fraction_evaluate=1.0,  # Utiliser 10% des clients pour l'évaluation\n",
    "        min_fit_clients=NUM_CLIENTS,  # Minimum de 10 clients pour l'entraînement\n",
    "        min_evaluate_clients=NUM_CLIENTS,  # Minimum de 5 clients pour l'évaluation\n",
    "        min_available_clients=NUM_CLIENTS,\n",
    "        evaluate_fn=evaluate\n",
    "    )\n",
    "    \n",
    "    \n",
    "    config = ServerConfig(num_rounds=MAX_ROUND)\n",
    "    return ServerAppComponents(strategy=strategy, config=config)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93457c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=10, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
      "\u001b[36m(ClientAppActor pid=139062)\u001b[0m /home/stagiaire-stack/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "\u001b[36m(ClientAppActor pid=139062)\u001b[0m   warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
      "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=139062)\u001b[0m [Client 7] get_parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[91mERROR \u001b[0m:     ServerApp thread raised an exception: mat1 and mat2 shapes cannot be multiplied (32x97 and 96x90)\n",
      "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
      "  File \"/home/stagiaire-stack/.local/lib/python3.10/site-packages/flwr/simulation/run_simulation.py\", line 268, in server_th_with_start_checks\n",
      "    updated_context = _run(\n",
      "  File \"/home/stagiaire-stack/.local/lib/python3.10/site-packages/flwr/server/run_serverapp.py\", line 62, in run\n",
      "    server_app(grid=grid, context=context)\n",
      "  File \"/home/stagiaire-stack/.local/lib/python3.10/site-packages/flwr/server/server_app.py\", line 142, in __call__\n",
      "    start_grid(\n",
      "  File \"/home/stagiaire-stack/.local/lib/python3.10/site-packages/flwr/server/compat/app.py\", line 90, in start_grid\n",
      "    hist = run_fl(\n",
      "  File \"/home/stagiaire-stack/.local/lib/python3.10/site-packages/flwr/server/server.py\", line 492, in run_fl\n",
      "    hist, elapsed_time = server.fit(\n",
      "  File \"/home/stagiaire-stack/.local/lib/python3.10/site-packages/flwr/server/server.py\", line 95, in fit\n",
      "    res = self.strategy.evaluate(0, parameters=self.parameters)\n",
      "  File \"/home/stagiaire-stack/.local/lib/python3.10/site-packages/flwr/server/strategy/fedavg.py\", line 167, in evaluate\n",
      "    eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})\n",
      "  File \"/tmp/ipykernel_138548/3940624794.py\", line 10, in evaluate\n",
      "    loss, accuracy = test(net, testloader)\n",
      "  File \"/tmp/ipykernel_138548/555561515.py\", line 54, in test\n",
      "    outputs = net(X)  # shape: [B, 15]\n",
      "  File \"/home/stagiaire-stack/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/stagiaire-stack/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_138548/3114439012.py\", line 13, in forward\n",
      "    return self.layers(x)\n",
      "  File \"/home/stagiaire-stack/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/stagiaire-stack/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/stagiaire-stack/.local/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 250, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/stagiaire-stack/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/stagiaire-stack/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/stagiaire-stack/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (32x97 and 96x90)\n",
      "\n",
      "Exception in thread Thread-7 (server_th_with_start_checks):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/stagiaire-stack/.local/lib/python3.10/site-packages/flwr/simulation/run_simulation.py\", line 268, in server_th_with_start_checks\n",
      "    updated_context = _run(\n",
      "  File \"/home/stagiaire-stack/.local/lib/python3.10/site-packages/flwr/server/run_serverapp.py\", line 62, in run\n",
      "    server_app(grid=grid, context=context)\n",
      "  File \"/home/stagiaire-stack/.local/lib/python3.10/site-packages/flwr/server/server_app.py\", line 142, in __call__\n",
      "    start_grid(\n",
      "  File \"/home/stagiaire-stack/.local/lib/python3.10/site-packages/flwr/server/compat/app.py\", line 90, in start_grid\n",
      "    hist = run_fl(\n",
      "  File \"/home/stagiaire-stack/.local/lib/python3.10/site-packages/flwr/server/server.py\", line 492, in run_fl\n",
      "    hist, elapsed_time = server.fit(\n",
      "  File \"/home/stagiaire-stack/.local/lib/python3.10/site-packages/flwr/server/server.py\", line 95, in fit\n",
      "    res = self.strategy.evaluate(0, parameters=self.parameters)\n",
      "  File \"/home/stagiaire-stack/.local/lib/python3.10/site-packages/flwr/server/strategy/fedavg.py\", line 167, in evaluate\n",
      "    eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})\n",
      "  File \"/tmp/ipykernel_138548/3940624794.py\", line 10, in evaluate\n",
      "  File \"/tmp/ipykernel_138548/555561515.py\", line 54, in test\n",
      "  File \"/home/stagiaire-stack/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/stagiaire-stack/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_138548/3114439012.py\", line 13, in forward\n",
      "  File \"/home/stagiaire-stack/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/stagiaire-stack/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/stagiaire-stack/.local/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 250, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/stagiaire-stack/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/stagiaire-stack/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/stagiaire-stack/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (32x97 and 96x90)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Exception in ServerApp thread",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_138548/1615678624.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m run_simulation(\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mserver_app\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mclient_app\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/flwr/simulation/run_simulation.py\u001b[0m in \u001b[0;36mrun_simulation\u001b[0;34m(server_app, client_app, num_supernodes, backend_name, backend_config, enable_tf_gpu_growth, verbose_logging)\u001b[0m\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     _ = _run_simulation(\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0mnum_supernodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_supernodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mclient_app\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient_app\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/flwr/simulation/run_simulation.py\u001b[0m in \u001b[0;36m_run_simulation\u001b[0;34m(num_supernodes, exit_event, client_app, server_app, backend_name, backend_config, client_app_attr, server_app_attr, server_app_run_config, app_dir, flwr_dir, run, enable_tf_gpu_growth, verbose_logging, is_app)\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_logger_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         \u001b[0mupdated_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_main_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mupdated_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/flwr/simulation/run_simulation.py\u001b[0m in \u001b[0;36m_main_loop\u001b[0;34m(num_supernodes, backend_name, backend_config_stream, app_dir, is_app, enable_tf_gpu_growth, run, exit_event, flwr_dir, client_app, client_app_attr, server_app, server_app_attr, server_app_run_config)\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0mserverapp_th\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mserver_app_thread_has_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Exception in ServerApp thread\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEBUG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopping Simulation Engine now.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Exception in ServerApp thread"
     ]
    }
   ],
   "source": [
    "app = ServerApp(server_fn=server_fn)\n",
    "\n",
    "server = ServerApp(server_fn=server_fn)\n",
    "backend_config = {\"client_resources\": None}\n",
    "\n",
    "\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_PARTITIONS,\n",
    "    backend_config=backend_config,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173e60e1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5775871f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
